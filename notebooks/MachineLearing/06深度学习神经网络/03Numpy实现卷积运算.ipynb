{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da12652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e322a",
   "metadata": {},
   "source": [
    "# Implementing convolution operations with numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3154014",
   "metadata": {},
   "source": [
    "## Single-channel convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5363e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_conv(inputs, filter, _result, padding = \"VALID\"):\n",
    "    H, W = inputs.shape\n",
    "    filter_size = filter.shape[0]\n",
    "    # floor\n",
    "    filter_center = int(filter_size / 2.0)\n",
    "    filter_center_ceil = int(np.ceil(filter_size / 2.0))\n",
    "\n",
    "    # Define a space of the same size as the input, but the surrounding circle will be cut off afterward.\n",
    "    result = np.zeros((_result.shape))\n",
    "    # Update input (In SAME mode, HW will be changed.\n",
    "    # H, W = inputs.shape\n",
    "    # print(\"new size\", H, W)\n",
    "    for r in range(0, H - filter_size + 1):\n",
    "        for c in range(0, W - filter_size + 1):\n",
    "            # The input region of the convolution kernel size\n",
    "            cur_input = inputs[r:r + filter_size, c:c + filter_size]\n",
    "            # The input of kernel size is multiplied by the convolution kernel\n",
    "            cur_output = cur_input * filter\n",
    "            # Then sum all the values\n",
    "            conv_sum = np.sum(cur_output)\n",
    "            # Current point output value\n",
    "            result[r, c] = conv_sum\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a024bc2",
   "metadata": {},
   "source": [
    "## Multi-channel convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37325650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv(inputs, filter, strides = [1, 1], padding = \"SAME\"):\n",
    "    C_in, H, W = inputs.shape\n",
    "    filter_size = filter.shape[2]\n",
    "    # The number of output channels, which is also the number of kernels\n",
    "    C_out = filter.shape[0]\n",
    "    if padding == \"VALID\":\n",
    "        result = np.zeros(\n",
    "            [C_out, int(np.ceil(H - filter_size + 1) / strides[0]), int(np.ceil(W - filter_size + 1) / strides[1])],\n",
    "            np.float32)\n",
    "    else:\n",
    "        result = np.zeros([C_out, int(H / strides[0]), int(W / strides[1])], np.float32)\n",
    "        C, H_new, W_new = inputs.shape\n",
    "        pad_h = (H_new - 1) * strides[0] + filter_size - H\n",
    "        pad_top = int(pad_h / 2)\n",
    "        pad_down = pad_h - pad_top\n",
    "\n",
    "        pad_w = (W_new - 1) * strides[1] + filter_size - W\n",
    "        pad_left = int(pad_w / 2)\n",
    "        pad_right = pad_w - pad_left\n",
    "        inputs = np.pad(inputs, ((0, 0), (pad_top, pad_down), (pad_left, pad_right)), 'constant',\n",
    "                        constant_values = (0, 0))\n",
    "    for channel_out in range(C_out):\n",
    "        for channel_in in range(C_in):\n",
    "            # Data of the current channel\n",
    "            channel_data = inputs[channel_in]\n",
    "            # Single-core single-channel convolution, then accumulation\n",
    "            result[channel_out, :, :] += numpy_conv(channel_data, filter[channel_out][channel_in], result[0], padding)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa350dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " [[[ 0.  1.  2.  3.  4.  5.  6.  7.  8.]\n",
      "  [ 1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
      "  [ 2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "  [ 3.  4.  5.  6.  7.  8.  9. 10. 11.]\n",
      "  [ 4.  5.  6.  7.  8.  9. 10. 11. 12.]\n",
      "  [ 5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "  [ 6.  7.  8.  9. 10. 11. 12. 13. 14.]\n",
      "  [ 7.  8.  9. 10. 11. 12. 13. 14. 15.]\n",
      "  [ 8.  9. 10. 11. 12. 13. 14. 15. 16.]]\n",
      "\n",
      " [[ 1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
      "  [ 2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "  [ 3.  4.  5.  6.  7.  8.  9. 10. 11.]\n",
      "  [ 4.  5.  6.  7.  8.  9. 10. 11. 12.]\n",
      "  [ 5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "  [ 6.  7.  8.  9. 10. 11. 12. 13. 14.]\n",
      "  [ 7.  8.  9. 10. 11. 12. 13. 14. 15.]\n",
      "  [ 8.  9. 10. 11. 12. 13. 14. 15. 16.]\n",
      "  [ 9. 10. 11. 12. 13. 14. 15. 16. 17.]]\n",
      "\n",
      " [[ 2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "  [ 3.  4.  5.  6.  7.  8.  9. 10. 11.]\n",
      "  [ 4.  5.  6.  7.  8.  9. 10. 11. 12.]\n",
      "  [ 5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "  [ 6.  7.  8.  9. 10. 11. 12. 13. 14.]\n",
      "  [ 7.  8.  9. 10. 11. 12. 13. 14. 15.]\n",
      "  [ 8.  9. 10. 11. 12. 13. 14. 15. 16.]\n",
      "  [ 9. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "  [10. 11. 12. 13. 14. 15. 16. 17. 18.]]] \n",
      "\n",
      "filter\n",
      " [[[[0. 1. 2.]\n",
      "   [1. 2. 3.]\n",
      "   [2. 3. 4.]]\n",
      "\n",
      "  [[1. 2. 3.]\n",
      "   [2. 3. 4.]\n",
      "   [3. 4. 5.]]\n",
      "\n",
      "  [[2. 3. 4.]\n",
      "   [3. 4. 5.]\n",
      "   [4. 5. 6.]]]\n",
      "\n",
      "\n",
      " [[[1. 2. 3.]\n",
      "   [2. 3. 4.]\n",
      "   [3. 4. 5.]]\n",
      "\n",
      "  [[2. 3. 4.]\n",
      "   [3. 4. 5.]\n",
      "   [4. 5. 6.]]\n",
      "\n",
      "  [[3. 4. 5.]\n",
      "   [4. 5. 6.]\n",
      "   [5. 6. 7.]]]] \n",
      "\n",
      "result\n",
      " [[[ 110.  186.  249.  312.  375.  438.  501.  564.  338.]\n",
      "  [ 186.  297.  378.  459.  540.  621.  702.  783.  456.]\n",
      "  [ 249.  378.  459.  540.  621.  702.  783.  864.  501.]\n",
      "  [ 312.  459.  540.  621.  702.  783.  864.  945.  546.]\n",
      "  [ 375.  540.  621.  702.  783.  864.  945. 1026.  591.]\n",
      "  [ 438.  621.  702.  783.  864.  945. 1026. 1107.  636.]\n",
      "  [ 501.  702.  783.  864.  945. 1026. 1107. 1188.  681.]\n",
      "  [ 564.  783.  864.  945. 1026. 1107. 1188. 1269.  726.]\n",
      "  [ 338.  456.  501.  546.  591.  636.  681.  726.  398.]]\n",
      "\n",
      " [[ 134.  231.  312.  393.  474.  555.  636.  717.  446.]\n",
      "  [ 231.  378.  486.  594.  702.  810.  918. 1026.  627.]\n",
      "  [ 312.  486.  594.  702.  810.  918. 1026. 1134.  690.]\n",
      "  [ 393.  594.  702.  810.  918. 1026. 1134. 1242.  753.]\n",
      "  [ 474.  702.  810.  918. 1026. 1134. 1242. 1350.  816.]\n",
      "  [ 555.  810.  918. 1026. 1134. 1242. 1350. 1458.  879.]\n",
      "  [ 636.  918. 1026. 1134. 1242. 1350. 1458. 1566.  942.]\n",
      "  [ 717. 1026. 1134. 1242. 1350. 1458. 1566. 1674. 1005.]\n",
      "  [ 446.  627.  690.  753.  816.  879.  942. 1005.  590.]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# input[C_in,H,W]\n",
    "inputs = np.zeros([3,9,9])\n",
    "for i in range(3):\n",
    "    for j in range(9):\n",
    "        for z in range(9):\n",
    "            inputs[i][j][z] = i+j+z\n",
    "\n",
    "print(\"input:\\n\",inputs,\"\\n\")\n",
    "\n",
    "#kernel[C_out,C_in,K,K]\n",
    "filter = np.zeros([2, 3, 3, 3])\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        for x in range(3):\n",
    "            for y in range(3):\n",
    "                filter[i][j][x][y] = i + j + x + y\n",
    "\n",
    "\n",
    "print(\"filter\\n\",filter,\"\\n\")\n",
    "\n",
    "final_result = _conv(inputs, filter, strides=[1,1],padding=\"SAME\")\n",
    "\n",
    "print(\"result\\n\",final_result,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f21b313",
   "metadata": {},
   "source": [
    "# Implementing dropout with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8151dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropoutLayer(object):\n",
    "    def __init__(self, keep_prob):\n",
    "        \"\"\"\n",
    "        :param keep_prob - probability that given unit will not be dropped out\n",
    "        \"\"\"\n",
    "        self._keep_prob = keep_prob\n",
    "        self.mask = None\n",
    "    \n",
    "    def forward_pass(self, a_prev: np.array, training: bool) -> np.array:\n",
    "        if training:\n",
    "            self._mask = (np.random.rand(*a_prev.shape) < self._keep_prob) # Calculate mask\n",
    "            return self._apply_mask(a_prev, self._mask) # Dropout\n",
    "        else:\n",
    "            return a_prev\n",
    "    \n",
    "    def backward_pass(self, da_curr: np.array) -> np.array:\n",
    "        return self._apply_mask(da_curr, self._mask)\n",
    "    \n",
    "    def _apply_mask(self, array: np.array, mask: np.array) -> np.array:\n",
    "        array *= mask\n",
    "        array /= self._keep_prob \n",
    "        # Divide by the ratio, keep the total unchanged, and avoid affecting the output result\n",
    "\n",
    "        return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b7e38de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[2., 7., 5., 4., 6., 9., 8., 5.],\n",
       "         [8., 5., 9., 4., 4., 6., 6., 3.],\n",
       "         [7., 2., 5., 9., 2., 3., 8., 3.],\n",
       "         [9., 4., 5., 9., 8., 6., 8., 8.],\n",
       "         [3., 5., 8., 3., 4., 4., 7., 8.],\n",
       "         [8., 1., 5., 1., 2., 8., 4., 2.],\n",
       "         [1., 8., 8., 6., 4., 9., 8., 8.],\n",
       "         [1., 8., 9., 7., 1., 9., 7., 3.]],\n",
       "\n",
       "        [[4., 6., 6., 1., 2., 3., 9., 9.],\n",
       "         [2., 4., 5., 5., 8., 7., 6., 6.],\n",
       "         [7., 4., 5., 2., 3., 4., 7., 9.],\n",
       "         [6., 4., 3., 2., 8., 7., 2., 8.],\n",
       "         [9., 7., 5., 1., 7., 8., 4., 6.],\n",
       "         [7., 6., 3., 9., 7., 4., 3., 8.],\n",
       "         [8., 4., 4., 8., 9., 1., 9., 3.],\n",
       "         [5., 8., 4., 7., 7., 6., 3., 4.]],\n",
       "\n",
       "        [[7., 2., 6., 8., 3., 3., 2., 8.],\n",
       "         [5., 1., 5., 4., 7., 1., 4., 4.],\n",
       "         [3., 7., 9., 3., 9., 7., 1., 1.],\n",
       "         [2., 7., 6., 6., 1., 2., 4., 8.],\n",
       "         [2., 2., 8., 8., 8., 2., 1., 6.],\n",
       "         [2., 4., 5., 1., 2., 7., 3., 1.],\n",
       "         [5., 8., 2., 5., 4., 7., 8., 3.],\n",
       "         [8., 7., 3., 4., 5., 3., 1., 2.]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_prev=np.random.randint(1,10,[1,3,8,8]).astype(np.float64)\n",
    "a_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89adb147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0., 14.,  0.,  8.,  0.,  0., 16.,  0.],\n",
       "         [ 0.,  0., 18.,  0.,  8., 12., 12.,  0.],\n",
       "         [14.,  0., 10.,  0.,  4.,  6., 16.,  6.],\n",
       "         [ 0.,  0., 10., 18., 16.,  0.,  0.,  0.],\n",
       "         [ 0., 10., 16.,  6.,  8.,  0., 14., 16.],\n",
       "         [16.,  0., 10.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0., 16.,  0.,  0.,  8., 18.,  0., 16.],\n",
       "         [ 2.,  0.,  0., 14.,  2., 18., 14.,  6.]],\n",
       "\n",
       "        [[ 8., 12., 12.,  2.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  8.,  0., 10.,  0.,  0., 12.,  0.],\n",
       "         [14.,  0.,  0.,  0.,  0.,  0.,  0., 18.],\n",
       "         [12.,  8.,  0.,  0., 16.,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 10.,  0., 14.,  0.,  0.,  0.],\n",
       "         [14., 12.,  6.,  0., 14.,  0.,  0., 16.],\n",
       "         [16.,  8.,  0.,  0.,  0.,  2.,  0.,  0.],\n",
       "         [ 0., 16.,  8.,  0.,  0., 12.,  0.,  8.]],\n",
       "\n",
       "        [[14.,  4.,  0., 16.,  6.,  0.,  4., 16.],\n",
       "         [10.,  2., 10.,  0.,  0.,  0.,  8.,  8.],\n",
       "         [ 0., 14.,  0.,  0.,  0., 14.,  2.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  4.,  0., 12.],\n",
       "         [ 0.,  8., 10.,  2.,  4., 14.,  6.,  2.],\n",
       "         [ 0.,  0.,  0., 10.,  8., 14., 16.,  0.],\n",
       "         [ 0., 14.,  0.,  0.,  0.,  6.,  0.,  4.]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout=DropoutLayer(keep_prob=0.5)\n",
    "out=dropout.forward_pass(a_prev,training=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f7c68",
   "metadata": {},
   "source": [
    "# Implementing pooling with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6367cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Tuple\n",
    "\n",
    "class MaxPoolLayer(object):\n",
    "    def __init__(self, pool_size: Tuple[int, int], stride: int = 2):\n",
    "        \"\"\"\n",
    "        :param pool_size - tuple holding shape of 2D pooling window\n",
    "        :param stride - stride along width and height of input volume used to\n",
    "        apply pooling operation\n",
    "        \"\"\"\n",
    "        self._pool_size = pool_size\n",
    "        self._stride = stride\n",
    "        self._a = None\n",
    "        self._cache = {}\n",
    "    \n",
    "    def forward_pass(self, a_prev: np.array, training: bool) -> np.array:\n",
    "        \"\"\"\n",
    "        :param a_prev - 4D tensor with shape(n, h_in, w_in, c)\n",
    "        :output 4D tensor with shape(n, h_out, w_out, c)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        w_in - width of input volume\n",
    "        h_in - width of input volume\n",
    "        c - number of channels of the input/output volume\n",
    "        w_out - width of output volume\n",
    "        h_out - width of output volume\n",
    "        \"\"\"\n",
    "        self._a = np.array(a_prev, copy = True)\n",
    "        n, h_in, w_in, c = a_prev.shape\n",
    "        h_pool, w_pool = self._pool_size\n",
    "        h_out = 1 + (h_in - h_pool) // self._stride\n",
    "        w_out = 1 + (w_in - w_pool) // self._stride\n",
    "        output = np.zeros((n, h_out, w_out, c))\n",
    "\n",
    "        for i in range(h_out):\n",
    "            for j in range(w_out):\n",
    "                h_start = i * self._stride\n",
    "                h_end = h_start + h_pool\n",
    "                w_start = j * self._stride\n",
    "                w_end = w_start + w_pool\n",
    "                a_prev_slice = a_prev[:, h_start:h_end, w_start:w_end, :]\n",
    "                self._save_mask(x = a_prev_slice, cords = (i, j))\n",
    "                output[:, i, j, :] = np.max(a_prev_slice, axis = (1, 2))\n",
    "        return output\n",
    "    \n",
    "    def backward_pass(self, da_curr: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        :param da_curr - 4D tensor with shape(n, h_out, w_out, c)\n",
    "        :output 4D tensor with shape(n, h_in, w_in, c)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        w_in - width of input volume\n",
    "        h_in - width of input volume\n",
    "        c - number of channels of the input/output volume\n",
    "        w_out - width of output volume\n",
    "        h_out - width of output volume\n",
    "        \"\"\"\n",
    "        output = np.zeros_like(self._a)\n",
    "        _, h_out, w_out = da_curr.shape\n",
    "        h_pool, w_pool = self._pool_size\n",
    "\n",
    "        for i in range(h_out):\n",
    "            for j in range(w_out):\n",
    "                h_start = i * self._stride\n",
    "                h_end = h_start + h_pool\n",
    "                w_start = j * self._stride\n",
    "                w_end = w_start + w_pool\n",
    "                output[:, h_start:h_end, w_start:w_end, :] += \\\n",
    "                    da_curr[:, i:i + 1, j:j + 1, :] * self._cache[(i, j)]\n",
    "        return output       \n",
    "\n",
    "    def _save_mask(self, x: np.array, cords: Tuple[int, int]) -> None:\n",
    "        mask = np.zeros_like(x)\n",
    "        n, h, w, c = x.shape\n",
    "        x = x.reshape(n, h * w, c)\n",
    "        idx = np.argmax(x, axis = 1)\n",
    "\n",
    "        n_idx, c_idx = np.indices((n, c))\n",
    "        mask.reshape(n, h * w, c)[n_idx, idx, c_idx] = 1\n",
    "        self._cache[cords] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed148d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[3., 5., 4., 4., 6., 9., 2., 6.],\n",
       "         [1., 8., 6., 3., 8., 9., 7., 9.],\n",
       "         [5., 7., 3., 5., 8., 3., 5., 6.],\n",
       "         [3., 6., 6., 9., 5., 6., 9., 4.],\n",
       "         [7., 9., 4., 5., 3., 5., 6., 9.],\n",
       "         [2., 8., 1., 8., 4., 9., 2., 2.],\n",
       "         [3., 1., 9., 3., 1., 2., 9., 4.],\n",
       "         [7., 3., 9., 1., 8., 1., 8., 3.]],\n",
       "\n",
       "        [[7., 6., 7., 9., 1., 5., 3., 9.],\n",
       "         [7., 9., 2., 7., 2., 2., 4., 8.],\n",
       "         [7., 1., 4., 5., 3., 3., 4., 6.],\n",
       "         [9., 2., 4., 2., 8., 7., 1., 1.],\n",
       "         [3., 1., 9., 9., 3., 6., 3., 1.],\n",
       "         [3., 1., 3., 8., 9., 1., 5., 4.],\n",
       "         [7., 7., 2., 8., 8., 4., 4., 2.],\n",
       "         [7., 1., 9., 1., 2., 4., 1., 1.]],\n",
       "\n",
       "        [[5., 8., 5., 4., 3., 2., 8., 3.],\n",
       "         [6., 6., 4., 2., 3., 4., 3., 9.],\n",
       "         [9., 4., 1., 6., 6., 3., 7., 6.],\n",
       "         [7., 7., 2., 9., 6., 3., 9., 9.],\n",
       "         [3., 6., 4., 9., 8., 2., 4., 3.],\n",
       "         [4., 3., 9., 4., 1., 1., 7., 4.],\n",
       "         [8., 6., 2., 4., 1., 9., 7., 1.],\n",
       "         [9., 6., 1., 6., 9., 1., 1., 1.]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_prev=np.random.randint(1,10,[1,8,8,3]).astype(np.float64)\n",
    "a_prev.transpose(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e68e835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[8., 6., 9., 9.],\n",
       "         [7., 9., 8., 9.],\n",
       "         [9., 8., 9., 9.],\n",
       "         [7., 9., 8., 9.]],\n",
       "\n",
       "        [[9., 9., 5., 9.],\n",
       "         [9., 5., 8., 6.],\n",
       "         [3., 9., 9., 5.],\n",
       "         [7., 9., 8., 4.]],\n",
       "\n",
       "        [[8., 5., 4., 9.],\n",
       "         [9., 9., 6., 9.],\n",
       "         [6., 9., 8., 7.],\n",
       "         [9., 6., 9., 7.]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxpool=MaxPoolLayer(pool_size=(2,2),stride=2)\n",
    "out=maxpool.forward_pass(a_prev,training=True)\n",
    "out.transpose(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5cde7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
