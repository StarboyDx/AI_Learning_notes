{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8f660c7",
   "metadata": {},
   "source": [
    "# 1. A function for reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2979de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def readtxt(path, encoding):\n",
    "    with open(path, 'r', encoding = encoding) as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "\n",
    "def fileWalker(path):\n",
    "    fileArray = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for fn in files:\n",
    "            # eachpath = str(root + '/' + fn) #Linux\n",
    "            eachpath = os.path.join(root, fn)  # Automatically adapts to separators of Windows/Linux/Mac\n",
    "            fileArray.append(eachpath)\n",
    "    return fileArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd5d68",
   "metadata": {},
   "source": [
    "# 2. Use regular expressions to split text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "210bfb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_parser(email_path):\n",
    "    punctuations = \"\"\",.<>()*&^%$#@!'\";~`[]{}|ã€\\\\/~+_-=?\"\"\"\n",
    "    content_list = readtxt(email_path, 'utf8')\n",
    "    content = (' '.join(content_list)).replace('\\r\\n', ' ').replace('\\t', ' ')\n",
    "    clean_word = []\n",
    "    # for punctuation in punctuations:\n",
    "    #     content = (' '.join(content.split(punctuation))).replace('  ', ' ')\n",
    "    #     clean_word = [word.lower()\n",
    "    #                   for word in content.split(' ') if len(word) > 2]\n",
    "    # Modify to avoid repeated generation\n",
    "    for punctuation in punctuations:\n",
    "        content = ' '.join(content.split(punctuation))\n",
    "    while '  ' in content:\n",
    "        content = content.replace('  ', ' ')\n",
    "    clean_word = [word.lower() for word in content.split(' ') if len(word) > 2]\n",
    "    return clean_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7889c566",
   "metadata": {},
   "source": [
    "# 3. Create a dictionary to count word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4aa5595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_prob(email_list, union_set):\n",
    "    word_prob = {}\n",
    "    for word in union_set:\n",
    "        counter = 0\n",
    "        for email in email_list:\n",
    "            if word in email:\n",
    "                counter += 1\n",
    "            else:\n",
    "                continue\n",
    "        prob = 0.0\n",
    "        if counter != 0:\n",
    "            prob = counter / len(email_list)\n",
    "        else:\n",
    "            prob = 0.01\n",
    "        word_prob[word] = prob\n",
    "    return word_prob\n",
    "\n",
    "def get_word(email_file):\n",
    "    word_list = []\n",
    "    word_set = []\n",
    "    email_paths = fileWalker(email_file)\n",
    "    for email_path in email_paths:\n",
    "        clean_word = email_parser(email_path)\n",
    "        word_list.append(clean_word)\n",
    "        word_set.extend(clean_word)\n",
    "    return word_list, set(word_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b978d5",
   "metadata": {},
   "source": [
    "# 4. Implementation of Naive Bayes Algorithm for Spam Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16bc6d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfilter(ham_word_pro, spam_word_pro, test_file):\n",
    "    test_paths = fileWalker(test_file)\n",
    "    for test_path in test_paths:\n",
    "        email_spam_prob = 0.0 # Initialization\n",
    "        # prior probability:\n",
    "        spam_prob = 0.5 # P(spam)\n",
    "        ham_prob = 0.5 # P(ham)\n",
    "\n",
    "        file_name = test_path.split('\\\\')[-1]\n",
    "        prob_dict = {}\n",
    "        words = set(email_parser(test_path)) # Store the probability that emails containing each word are spam, corresponding to each word.\n",
    "        for word in words:\n",
    "            Psw = 0.0 # Initialize P(spam|word) to 0.0\n",
    "            # Case 1: If the word is not in the spam word probability dictionary (has not appeared in the training set), assign a default value of 0.4\n",
    "            if word not in spam_word_pro:\n",
    "                Psw = 0.4\n",
    "            # Case 2: The word has appeared in the training set, and the Bayesian formula is used to calculate P(spam | word)\n",
    "            else:\n",
    "                # Extract the conditional probabilities calculated from the training set\n",
    "                Pws = spam_word_pro[word] # P(word|spam)\n",
    "                Pwh = ham_word_pro[word] # P(word|ham)\n",
    "\n",
    "                # Core formula: Bayes' theorem for calculating P(spam|word)\n",
    "                # P(spam|word) = [P(word|spam) * P(spam)] / [P(word|normal email) * P(normal email) + P(word|spam) * P(spam)]\n",
    "                Psw = spam_prob * (Pws / ((Pwh * ham_prob + Pws * spam_prob)))\n",
    "            prob_dict[word] = Psw\n",
    "        # Combine the probabilities of all words to calculate the final probability that the email is a spam.\n",
    "        numerator = 1\n",
    "        denominator_h = 1\n",
    "        # Iterate through the probabilities of all words and calculate the product\n",
    "        for k, v in prob_dict.items():\n",
    "            numerator *= v\n",
    "            denominator_h *= (1 - v)\n",
    "        # Final probability: P(spam | all words) = numerator / (numerator + denominator normal term)\n",
    "        email_spam_prob = round(numerator / (numerator + denominator_h), 4)\n",
    "\n",
    "        if email_spam_prob > 0.5:\n",
    "            print(file_name, 'spam', email_spam_prob)\n",
    "        else:\n",
    "            print(file_name, 'ham', email_spam_prob)\n",
    "        \n",
    "        print(prob_dict)\n",
    "        print('***********************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3db7eee",
   "metadata": {},
   "source": [
    "# 5. Main function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a3cb71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.txt ham 0.0\n",
      "{'keep': 0.19999999999999998, 'town': 0.19999999999999998, 'and': 0.5, 'while': 0.19999999999999998, 'out': 0.11111111111111112, 'going': 0.058823529411764705, 'jose': 0.19999999999999998, 'peter': 0.034482758620689655, 'eugene': 0.19999999999999998, 'to\\n': 0.19999999999999998, 'stuff': 0.11111111111111112, 'interesting': 0.11111111111111112, 'things\\n': 0.19999999999999998, 'with': 0.125, 'meet': 0.19999999999999998, 'let': 0.33333333333333337, 'you': 0.4230769230769231, 'want': 0.19999999999999998, 'some': 0.07692307692307693, 'once': 0.19999999999999998, 'know\\n': 0.19999999999999998}\n",
      "***********************************************************\n",
      "10.txt spam 1.0\n",
      "{'prices': 0.6666666666666667, 'drugs': 0.888888888888889, 'superb': 0.888888888888889, 'cards': 0.888888888888889, 'and': 0.5, 'required\\n': 0.923076923076923, 'online': 0.8750000000000001, 'canadian': 0.923076923076923, 'fda': 0.888888888888889, 'noprescription': 0.923076923076923, 'ordercializviagra': 0.888888888888889, 'only': 0.5714285714285714, 'pharmacy': 0.888888888888889, 'quality': 0.9523809523809523, '0nline': 0.888888888888889, 'save': 0.9411764705882353, 'approved': 0.888888888888889, 'all': 0.5555555555555556, 'major': 0.923076923076923, 'accept': 0.6, 'credit': 0.923076923076923, 'buy': 0.9729729729729729, 'wholesale': 0.888888888888889}\n",
      "***********************************************************\n",
      "2.txt ham 0.0\n",
      "{'working': 0.11111111111111112, 'both': 0.19999999999999998, 'the': 0.19999999999999998, 'management': 0.19999999999999998, 'and': 0.5, 'more': 0.625, 'done': 0.11111111111111112, 'art': 0.19999999999999998, 'way': 0.11111111111111112, 'yay': 0.19999999999999998, 'top': 0.6666666666666667, 'right': 0.11111111111111112, 'focusing': 0.19999999999999998, 'approach': 0.19999999999999998, 'creative': 0.19999999999999998, 'cca': 0.19999999999999998, 'strategy': 0.19999999999999998, 'you': 0.4230769230769231, 'today': 0.5, 'doing': 0.11111111111111112, 'strategic': 0.19999999999999998, 'program': 0.19999999999999998, 'design': 0.19999999999999998, 'mba': 0.19999999999999998, 'school': 0.19999999999999998, 'brained': 0.19999999999999998, 'new': 0.07692307692307693, 'fine': 0.19999999999999998}\n",
      "***********************************************************\n",
      "3.txt ham 0.0\n",
      "{'fans': 0.19999999999999998, 'take': 0.11111111111111112, 'we\\n': 0.19999999999999998, 'the': 0.19999999999999998, 'when': 0.19999999999999998, 'and': 0.5, 'got': 0.07692307692307693, 'done': 0.11111111111111112, 'going': 0.058823529411764705, 'about': 0.058823529411764705, 'time': 0.25, 'game': 0.19999999999999998, 'what': 0.11111111111111112, 'email': 0.058823529411764705, 'stuff': 0.11111111111111112, 'had': 0.19999999999999998, 'with': 0.125, 'are': 0.034482758620689655, 'food': 0.19999999999999998, 'museum': 0.19999999999999998, 'that': 0.2222222222222222, 'computer': 0.19999999999999998, 'cold': 0.11111111111111112, 'talked': 0.19999999999999998, 'rain': 0.19999999999999998, 'yesterday': 0.19999999999999998, 'get': 0.4285714285714285, 'train': 0.19999999999999998, 'not': 0.058823529411764705, 'john': 0.19999999999999998, 'some': 0.07692307692307693, 'riding': 0.19999999999999998, 'same': 0.19999999999999998, 'all': 0.5555555555555556, 'giants': 0.19999999999999998, 'drunk': 0.19999999999999998, 'there': 0.04, 'was': 0.047619047619047616, 'had\\n': 0.19999999999999998, 'free': 0.5, 'they': 0.07692307692307693, 'went': 0.11111111111111112, 'bike': 0.19999999999999998}\n",
      "***********************************************************\n",
      "4.txt ham 0.0\n",
      "{'working': 0.11111111111111112, 'the': 0.19999999999999998, 'having': 0.19999999999999998, 'like': 0.058823529411764705, 'been': 0.11111111111111112, 'jqplot': 0.19999999999999998, 'and': 0.5, 'running': 0.19999999999999998, 'website': 0.19999999999999998, 'from': 0.2727272727272727, 'using': 0.11111111111111112, 'far': 0.19999999999999998, 'right': 0.11111111111111112, 'plugin': 0.19999999999999998, 'away': 0.19999999999999998, 'jquery': 0.19999999999999998, 'think': 0.11111111111111112, 'used': 0.6666666666666667, 'launch': 0.19999999999999998, 'would': 0.11111111111111112, 'you': 0.4230769230769231, 'prototype': 0.19999999999999998, 'not': 0.058823529411764705, 'too': 0.11111111111111112}\n",
      "***********************************************************\n",
      "5.txt ham 0.0\n",
      "{'who': 0.19999999999999998, 'mandarin\\n': 0.19999999999999998, 'job': 0.19999999999999998, 'that': 0.2222222222222222, 'station': 0.19999999999999998, 'the': 0.19999999999999998, 'with': 0.125, 'knew': 0.19999999999999998, 'python': 0.19999999999999998, 'could': 0.07692307692307693, 'there': 0.04, 'get': 0.4285714285714285, 'fbi': 0.19999999999999998, 'guy': 0.19999999999999998, 'was': 0.047619047619047616, 'and': 0.5, 'gas': 0.19999999999999998, 'told': 0.19999999999999998}\n",
      "***********************************************************\n",
      "6.txt spam 1.0\n",
      "{'2007': 0.7999999999999999, '119\\n': 0.7999999999999999, 'titles': 0.7999999999999999, 'extended\\n': 0.7999999999999999, 'and': 0.5, 'softwares\\n': 0.7999999999999999, 'more': 0.625, 'microsoft': 0.7999999999999999, 'acrobat': 0.7999999999999999, 'adobe': 0.7999999999999999, 'fast': 0.7999999999999999, 'plus': 0.7999999999999999, 'thousand': 0.7999999999999999, 'ultimate': 0.7999999999999999, 'oem': 0.7999999999999999, 'cs5': 0.7999999999999999, 'order': 0.9411764705882353, '129\\n': 0.7999999999999999, '2010': 0.5, 'professional': 0.5, 'photoshop': 0.7999999999999999, 'download\\n': 0.7999999999999999, 'windows': 0.5, 'office': 0.7999999999999999, 'pro': 0.7999999999999999}\n",
      "***********************************************************\n",
      "7.txt spam 1.0\n",
      "{'visa': 0.9523809523809523, '120': 0.9523809523809523, '50\\n': 0.888888888888889, '366': 0.888888888888889, '180': 0.923076923076923, '00\\n': 0.9411764705882353, 'phentermin': 0.888888888888889, 'bargains': 0.888888888888889, 'genuine': 0.888888888888889, 'cost\\n': 0.888888888888889, '292': 0.888888888888889, 'buy': 0.9729729729729729, 'accepted\\n': 0.888888888888889, '513': 0.888888888888889, 'here': 0.7999999999999999, 'low': 0.888888888888889, '130': 0.888888888888889, '219': 0.888888888888889}\n",
      "***********************************************************\n",
      "8.txt spam 1.0\n",
      "{'ofejacu1ate\\n': 0.9655172413793103, 'gains': 0.9655172413793103, 'and': 0.5, 'designed': 0.8750000000000001, 'intenseorgasns\\n': 0.9655172413793103, 'explosive': 0.9655172413793103, '100': 0.9795918367346939, 'length': 0.9655172413793103, 'volume': 0.9655172413793103, 'amazing': 0.9655172413793103, 'increase': 0.9655172413793103, 'harderecetions\\n': 0.9655172413793103, 'doctor': 0.9655172413793103, 'herbal': 0.9655172413793103, 'gain': 0.9655172413793103, 'have': 0.6428571428571428, 'safe': 0.9655172413793103, 'yourpenis': 0.9655172413793103, 'permanantly\\n': 0.9655172413793103, 'inches': 0.9696969696969697, 'thickness': 0.9655172413793103, 'you': 0.4230769230769231, 'everything': 0.9655172413793103, 'incredib1e': 0.9655172413793103, 'endorsed\\n': 0.9655172413793103, 'betterejacu1ation': 0.9655172413793103, 'rock': 0.9655172413793103, 'experience': 0.9696969696969697, 'natural': 0.9655172413793103, 'control\\n': 0.9655172413793103}\n",
      "***********************************************************\n",
      "9.txt spam 1.0\n",
      "{'visa': 0.9523809523809523, '120': 0.9523809523809523, '50\\n': 0.888888888888889, '366': 0.888888888888889, '180': 0.923076923076923, '00\\n': 0.9411764705882353, 'phentermin': 0.888888888888889, 'bargains': 0.888888888888889, 'genuine': 0.888888888888889, 'cost\\n': 0.888888888888889, '292': 0.888888888888889, 'buy': 0.9729729729729729, 'accepted\\n': 0.888888888888889, '513': 0.888888888888889, 'here': 0.7999999999999999, 'low': 0.888888888888889, '130': 0.888888888888889, '219': 0.888888888888889}\n",
      "***********************************************************\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    ham_file = 'data/email/ham'\n",
    "    spam_file = 'data/email/spam'\n",
    "    test_file = 'data/email/test'\n",
    "    ham_list, ham_set = get_word(ham_file)\n",
    "    spam_list, spam_set = get_word(spam_file)\n",
    "    union_set = ham_set | spam_set\n",
    "    ham_word_pro = count_word_prob(ham_list, union_set)\n",
    "    spam_word_pro = count_word_prob(spam_list, union_set)\n",
    "    myfilter(ham_word_pro, spam_word_pro, test_file)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60131c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
